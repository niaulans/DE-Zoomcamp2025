{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f847a99-f2c6-4d0c-be27-187543adcc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyarrow.parquet as pq\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec6e9c4-d0f8-4a37-a618-67cc4d428258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x71a53db2dc10>\n",
       "  created_by: parquet-cpp-arrow version 14.0.2\n",
       "  num_columns: 19\n",
       "  num_rows: 3646369\n",
       "  num_row_groups: 4\n",
       "  format_version: 2.6\n",
       "  serialized_size: 10797"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read metadata \n",
    "pq.read_metadata('yellow_tripdata_2024-11.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e8641a-937f-4e3a-afa1-cfbe1eadc3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID: int32\n",
       "tpep_pickup_datetime: timestamp[us]\n",
       "tpep_dropoff_datetime: timestamp[us]\n",
       "passenger_count: int64\n",
       "trip_distance: double\n",
       "RatecodeID: int64\n",
       "store_and_fwd_flag: large_string\n",
       "PULocationID: int32\n",
       "DOLocationID: int32\n",
       "payment_type: int64\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "congestion_surcharge: double\n",
       "Airport_fee: double"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file, read the table from file and check schema\n",
    "file = pq.ParquetFile('yellow_tripdata_2024-11.parquet')\n",
    "table = file.read()\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25084d9e-8231-41f8-b6e0-ba408b57a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3646369 entries, 0 to 3646368\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int32         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int32         \n",
      " 8   DOLocationID           int32         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  Airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(12), int32(3), int64(1), object(1)\n",
      "memory usage: 486.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert to pandas and check data\n",
    "df = table.to_pandas()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb5ba64-ced3-457f-9bb9-bb2bec72b68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x71a5438cd1f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an open SQL database connection object or a SQLAlchemy connectable\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc753a6-ff6c-4383-bf25-e4b858a4fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_trips (\n",
      "\t\"VendorID\" INTEGER, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" INTEGER, \n",
      "\t\"DOLocationID\" INTEGER, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\t\"Airport_fee\" FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate CREATE SQL statement from schema for validation\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_trips', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3709b4ea-0fce-4108-9609-b5a3e2a43443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is for testing\n",
    "\n",
    "# Creating batches of 100,000 for the paraquet file\n",
    "# batches_iter = file.iter_batches(batch_size=100000)\n",
    "# batches_iter\n",
    "\n",
    "# Take the first batch for testing\n",
    "# df = next(batches_iter).to_pandas()\n",
    "# df\n",
    "\n",
    "# Creating just the table in postgres\n",
    "#df.head(0).to_sql(name='ny_taxi_data',con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23889285-4e6e-4017-849f-2283621f4025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting batch 1...\n",
      "inserted! time taken      9.275 seconds.\n",
      "\n",
      "inserting batch 2...\n",
      "inserted! time taken      9.093 seconds.\n",
      "\n",
      "inserting batch 3...\n",
      "inserted! time taken      8.977 seconds.\n",
      "\n",
      "inserting batch 4...\n",
      "inserted! time taken      9.260 seconds.\n",
      "\n",
      "inserting batch 5...\n",
      "inserted! time taken      9.330 seconds.\n",
      "\n",
      "inserting batch 6...\n",
      "inserted! time taken      9.032 seconds.\n",
      "\n",
      "inserting batch 7...\n",
      "inserted! time taken      9.359 seconds.\n",
      "\n",
      "inserting batch 8...\n",
      "inserted! time taken      9.431 seconds.\n",
      "\n",
      "inserting batch 9...\n",
      "inserted! time taken      9.207 seconds.\n",
      "\n",
      "inserting batch 10...\n",
      "inserted! time taken      9.709 seconds.\n",
      "\n",
      "inserting batch 11...\n",
      "inserted! time taken      9.143 seconds.\n",
      "\n",
      "inserting batch 12...\n",
      "inserted! time taken      9.372 seconds.\n",
      "\n",
      "inserting batch 13...\n",
      "inserted! time taken      9.468 seconds.\n",
      "\n",
      "inserting batch 14...\n",
      "inserted! time taken      9.288 seconds.\n",
      "\n",
      "inserting batch 15...\n",
      "inserted! time taken      9.413 seconds.\n",
      "\n",
      "inserting batch 16...\n",
      "inserted! time taken      9.454 seconds.\n",
      "\n",
      "inserting batch 17...\n",
      "inserted! time taken      9.495 seconds.\n",
      "\n",
      "inserting batch 18...\n",
      "inserted! time taken      9.161 seconds.\n",
      "\n",
      "inserting batch 19...\n",
      "inserted! time taken      9.243 seconds.\n",
      "\n",
      "inserting batch 20...\n",
      "inserted! time taken      9.697 seconds.\n",
      "\n",
      "inserting batch 21...\n",
      "inserted! time taken      9.122 seconds.\n",
      "\n",
      "inserting batch 22...\n",
      "inserted! time taken      9.401 seconds.\n",
      "\n",
      "inserting batch 23...\n",
      "inserted! time taken      9.671 seconds.\n",
      "\n",
      "inserting batch 24...\n",
      "inserted! time taken      9.564 seconds.\n",
      "\n",
      "inserting batch 25...\n",
      "inserted! time taken      9.254 seconds.\n",
      "\n",
      "inserting batch 26...\n",
      "inserted! time taken      9.283 seconds.\n",
      "\n",
      "inserting batch 27...\n",
      "inserted! time taken      9.355 seconds.\n",
      "\n",
      "inserting batch 28...\n",
      "inserted! time taken      9.530 seconds.\n",
      "\n",
      "inserting batch 29...\n",
      "inserted! time taken      9.348 seconds.\n",
      "\n",
      "inserting batch 30...\n",
      "inserted! time taken      9.671 seconds.\n",
      "\n",
      "inserting batch 31...\n",
      "inserted! time taken      9.393 seconds.\n",
      "\n",
      "inserting batch 32...\n"
     ]
    }
   ],
   "source": [
    "# Insert values into the table \n",
    "t_start = time()\n",
    "count = 0\n",
    "for batch in file.iter_batches(batch_size=100000):\n",
    "    count+=1\n",
    "    batch_df = batch.to_pandas()\n",
    "    print(f'inserting batch {count}...')\n",
    "    b_start = time()\n",
    "    \n",
    "    batch_df.to_sql(name='yellow_taxi_trips',con=engine, if_exists='append')\n",
    "    b_end = time()\n",
    "    print(f'inserted! time taken {b_end-b_start:10.3f} seconds.\\n')\n",
    "    \n",
    "t_end = time()   \n",
    "print(f'Completed! Total time taken was {t_end-t_start:10.3f} seconds for {count} batches.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ae6fc-bd4d-4dc0-b37d-6c2591c98673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd \n",
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf426ca-d38b-4370-b9b1-c55d333e20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet'\n",
    "\n",
    "file_name = url.rsplit('/', 1)[-1].strip()\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e2f79-d1f4-4834-8520-a34dcaf2f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '.csv' in file_name:\n",
    "    print('yay') \n",
    "    df = pd.read_csv(file_name, nrows=10)\n",
    "    df_iter = pd.read_csv(file_name, iterator=True, chunksize=100000)\n",
    "elif '.parquet' in file_name:\n",
    "    print('oh yea')\n",
    "    file = pq.ParquetFile(file_name)\n",
    "    df = next(file.iter_batches(batch_size=10)).to_pandas()\n",
    "    df_iter = file.iter_batches(batch_size=100000)\n",
    "else: \n",
    "    print('Error. Only .csv or .parquet files allowed.')\n",
    "    sys.exit() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
